[![logo-name](https://github.com/openinfer/PrivateIdentity/blob/master/images/Private-Identity-Logo-Long.png)](https://www.private.id/)


## `Overview`

|  |  |
|--|--|
| <b>Benefits </b> | • **Face, voice and fingerprint recognition** <br>• **1:n continuous authentication** every 200ms <br>• **Unlimited user base** <br>• Fair, accurate and unbiased algorithms<br>• Preserves user privacy with fully homomorphic encryption<br>• Exempt from GDPR, CCPA, BIPA, and HIPAA privacy law obligations <br>• Decentralized client works with or without a network |
| **Solutions** | • **Verified Identity** <br>• **Web Sign-in** <br>• **Payments** <br>• **Phone Unlock** <br>• **Voice Auth for Amazon Connect** <br>• **Ticketless Access Control** <br>• Account Recovery <br>• Face CAPTCHA |
| **Face<br>Recognition** | **Uses any camera ≥0.3MP** (720P) [Face ≥244x244 Pixels] <br> On-device validation, liveness / anti-spoofing, encryption <br> Accommodates facemasks, glasses, distortions, rotations, facial hair, scars, makeup, filters, abrasions, and hue, saturation and light. <br> Identification Rate (IR) ≥99.71%, FPIR =0.001%, FNIR =0.025% |
| **Voice Recognition** |  **Uses 1 second of voice** (text- and language-independent) @ 16kHz<br> Uses 3 seconds of voice to support Amazon Connect @ 8kHz<br> On-device validation, liveness / anti-spoofing, encryption<br> Accommodates background noise, noise-canceling microphones, and sleepiness, smoking and alcohol.<br> Identification Rate (IR) ≥99.50%, FPIR=0.001%, FNIR=0.050% |
| **Fingerprint<br>Recognition** |  **Uses any camera ≥2MP** (1080P) [Finger ≥244x244 Pixels]<br> Continuous auth every 200ms<br> On-device validation, liveness / anti-spoofing, encryption<br> Accommodates distortions, rotations, scars, filters and abrasions.<br> Identification Rate (IR) ≥94.50%, FPIR=0.001%, FNIR=6.50% |
| **Channels** | **Chrome**, **Safari**, **Edge**, Firefox, Opera, Samsung Internet <br>**Windows**, **MacOS**, **iOS**, **Android**, **Linux**, **AWS**, **GCP**, **Azure** |
| **FHE** |  4KB fully homomorphic encrypted payloads (FHE payloads) <br> 10ms on-device encryption using neural network cryptography |
| **Privacy by design** |  **User’s biometric data remains private and secure**<br> Patented 1-way fully homomorphic encryption (FHE) certified compliant with IEEE 2410-2021 Standard for Biometric Privacy and ISO 27001/9001. Exempt from GDPR, CCPA, BIPA & HIPAA privacy law obligations |
| **Unbiased Algorithms** | Ethnically balanced training datasets and homogenized lighting algorithms prevent discrimination based on race, age, gender, or ethnicity. Accurately identifies all subgroups (IR ≥99.71%) in the DIF-CELEB-1M Diversity in Faces evaluation set. |
| **W3C WebAssembly** | Deploys instantly on Web browsers using secure C++ binary object code, DNNs compiled into runnable C++ libraries, and three layers of cryptography. Runs with or without Internet access. |
| **SDKs** | **C++, C#, Android, Python:** SDKs use a common C++ shareable object to enable developers to securely and privately register, predict, compare and delete users on major browsers, phones, embedded interfaces, and instruction sets, mobile devices, platforms, and public and private clouds, with or without Internet access. |
| **1:n biometric vector match** | Unlimited high-throughput 1:n biometric vector match computes identity without decrypt in 60ms constant time O(1)  at  ≥99.75% accuracy. Uses deep neural networks (DNNs) to accurately classify vectors irrespective of gallery size. |
| **1:1 biometric vector compare** | Compares the distance measurement of two or more embeddings against a cutoff in 10ms at ≥99.999% accuracy. |

## `Private ID System Description`	 
### `1. Introduction`
Private Identity<sup>®</sup> provides continuous biometric authentication every 200ms by combining the speed, accuracy, and security of embeddings with an extremely fast, accurate, and scalable ML vector matching service. This solution supports register once/auth everywhere, verified identity, payments, phone unlock, access control, and high-throughput biometric pipelines for an unlimited user base. 

The Private ID<sup>®</sup> client runs on-device to preserve privacy and is secure against adversaries willing to spend any amount of money and effort. To this end, the client is a small shareable object (.so) composed of immutable compiled native C++ binary object code, DNNs compiled into runnable C++ libraries, and three layers of cryptography. The client only stores and transmits embeddings (anonymized data) and runs on all modern browsers, phones, devices, embedded devices, and platforms using WebAssembly, C++, C#, Android, or Python. It operates with or without a network.

Embeddings output by the Private ID client are compact real-valued feature vector representations of unstructured biometric data that allow the biometric to be fully homomorphically encrypted (FHE). Specifically, these embeddings are anonymized, keyless, 1-way FHE payloads that are globally unique (i.e. no two embeddings are ever the same), positional arrays of 128 floating-point numbers that do not contain biological or behavioral characteristics, imagery, or a template of any physiological, biological or behavioral trait. These embeddings are a form of 1-way encryption as they cannot be used to recreate the initial input data but are distance measurable such that similarity between embeddings can be classified by a DNN.

Matching in the encrypted space using embeddings offers the highest level of privacy and exemption from privacy law obligations. Private ID’s ML vector match service returns identity in an incredibly fast 60ms constant time O(1) with >99.75% accuracy (FPIR=0.001), no matter how large the gallery size. Encrypted vector match is a relatively new FHE technique that uses complex, pre-trained DNNs (neural network cryptography) to generate distance-measurable 1-way FHE payloads. This technique was first described by Streit and colleagues (2017) [[link](https://arxiv.org/abs/1708.04726)] and patented by Private Identity in US Patent 10,419,221 (2019) and 10,721,070 (2020).

Private Identity’s FHE algorithm is a 1-way cryptographic hash that irreversibly encrypts biometric data while enabling match and search operations on the encrypted dataset. This privacy mitigates the regulatory and legal risk of biometric data. Indeed, the GDPR, CCPA, BIPA & HIPAA privacy laws specifically exclude and do not regulate anonymized data. Building on this, the new IEEE 2410-2021 Standard for Biometric Privacy provides that conforming FHE systems “do not incur GDPR, CCPA, BIPA or HIPAA privacy law obligations,” ensures that payloads are always 1-way fully homomorphically encrypted, and ensures no PII is received by the SBP server.

### `2. Helper Networks`
Private Identity’s “helper networks” find and validate the biometric, detect presentation attacks (spoofing) and blurry images, and augment biometric data prior to embedding. These helper networks are fully integrated into the Private ID client to prevent bad biometric inputs from harming the underlying identity system. The helper networks are described below and in US Patents 11,210,375 and 10,938,852.

***Landmark DNN.*** This geometry detection model accurately locates face(s) and finger(s) in an image by transforming each image into geometric primitives and measuring the relative position, width, and other parameters of eyes, mouth(s), nose(s), chin(s) and finger(s). The Landmark DNN returns x,y coordinates of each biometric factor in an image, video frame, or video stream, uses YOLO architecture, and is 100kB. The Landmark DNN is on (true) by default.

***Validation DNNs***. The face and fingerprint validation models accurately validate frontalized face input images or fingerprint input images. These Validation DNNs return a validation score between 0 to 100, where 100 is a perfect image. The Validation DNNs use MobileNetV2 architecture and are approximately 1.5MB. Both DNNs are on (true) by default.

The Voice Validation DNN validates audio input for a quality human voice to discriminate between a voice and external noise. The DNN accepts a sound wave as input and returns a validation score between 0 to 100, where 100 is perfect audio in which the voice is isolated enough to create a valid embedding. It uses YOLO architecture and is 100kB.

Wearing glasses or a facemask during biometric enrollment lowers subsequent prediction performance. The Three-Class Validation DNN determines if the face is not obstructed, obstructed with glasses (sunglasses or eyeglasses), or obstructed with a facemask. The Three Classes Detection DNN accepts one frontalized face input image and outputs three values summing to 100. The largest value among these three values predicts the class. This DNN uses YOLO architecture and is 100KB. The DNN is on (true) by default during enrollment.

***Blurry Detect DNN***. The blurry image detection model accurately detects cropped and aligned images that are validated by the Landmark DNN but too blurry to be processed by the Embedding DNN. The Blurry Detect DNN returns a score between 0 and 100, where 100 is not blurry. It uses YOLO architecture and is 100KB. This DNN is on (true) by default.

***Presentation attack DNNs***. Three presentation attack detection (PAD) DNNs provide active and passive facial liveness to ensure the identity system only processes live biometric data. One DNN detects image spoofing, one detects video spoofing, and the third DNN detects eyes open/eyes closed.

The Image Spoof Detection DNN provided passive facial liveness by detecting print image attacks. This mitigates the risk of an image spoofing attack during operation. This DNN receives an input image and outputs a validation score between 0 and 100, where 100 is a spoof. The user cannot proceed until a valid image is detected. It uses MobileNetV2 architecture and is 1.5MB. This DNN is on (true) by default.

The Video Spoof Detection DNN provides passive facial liveness by detecting a video image spoofing attack during operation. This mitigates the risk of a video spoofing attack. The DNN receives an input image and outputs a validation score between 0 and 100, where 100 is a spoof. The DNN uses MobileNetV2 architecture and is 1.5MB. It is on (true) by default.

The Eyes Open/Eyes Closed DNN provides active facial liveness by detecting the subject’s eyes in the open and closed positions. This mitigates the risk of authenticating a nonresponsive subject. The Eyes Open/Eyes Closed DNN receives an input image of an eye and outputs a validation score between 0 and 100, where 100 is eyes open. This DNN uses YOLO architecture and is 100kB. It is off (false) by default.

***Data augmentation.*** Once located and validated and prior to embedding, a procedural program augments every biometric sample to generalize enrollment and improve the accuracy and performance of subsequent predictions. Enrollment operations augment the original biometric 60 times (60x). Image augmentations included rotations, flips, and color and lighting homogenizations and increases the distance metric without exceeding class boundaries.

To augment voice samples, we modulate and transform each voice audio with pulse code modulation (PCM) and Fast Fourier Transform (FFT). PCM lessens the input to two times the frequency range allowing for the smallest possible Fourier transform without computational loss. FFT moves the PCM modulated audio signal from the time domain to a representation in the frequency domain. The transformed output is a two-dimensional array of frequencies. Audio augmentations broaden the digital signal to emulate different microphones, noise-canceling algorithms, normalized speaker distance from the microphone, and emulates various human physiological changes including lack of sleep, alcohol consumption, and smoking, and added random background noise. Each augmentation increases the distance similarity without surpassing class boundaries.

***Document Geometry Detection DNN***. To acquire a face or fingerprint from a government identity card or passport, the Document Geometry Detection DNN locates identity documents and face(s) or fingerprint(s) samples in the document by transforming each image into geometric primitives and measuring the relative position, width, and other parameters of the document and eyes, mouth(s), nose(s), chin(s) and finger(s). The DNN accepts image input and outputs (x,y) coordinates of the document and the biometric samples contained in the document. It uses YOLO architecture and is 100KB. The DNN is on (true) by default during photo ID verification.
### `3. Embedding DNNs`
Private Identity uses pre-trained “embedding DNNs” trained on a corpus of hundreds of millions of biometric images to convert unstructured dense individual raw biometric pixel intensities form images to real-valued, lower-dimensional, distance-measurable  dense vectors, also known as embeddings. These embedding DNNs use “one-shot learning” techniques to avoid the need to be retrained to recognize new subjects. One-shot learning saves compute and power that would otherwise be needed for retraining.

Private Identity uses three embedding DNNs, one each for face, voice and fingerprint, to accept plaintext input and produce distance-measurable embeddings. The embedding DNNs train using techniques first taught by Schroff and colleagues (Google Research) [[link](https://arxiv.org/abs/1503.03832)], and further developed in collaboration with Google’s TensorFlow® team.

The embedding DNNs use MobileNetV2 architecture and train on open-source celebrity datasets (i.e. VoxCeleb, Asian-Celeb). After each training iteration (~60 days), the “No Reference” data quality methodology repairs errors and class overlaps in the training data. We delete the softmax layer after triplet loss to reduce model size.

The facial recognition embedding DNN training dataset contains 131,000 classes and 262M distinct facial images augmented with facemasks. The fingerprint embedding DNN training dataset contains 8,000 classes and 800,000 distinct fingerprint images. The speaker identification (voice recognition) training dataset contains 31,000 classes with 12M distinct voice audios.

To further generalize training and accommodate a wide range of boundary conditions during operation, the facial recognition embedding DNN dataset is randomly augmented during training to add eyeglasses, sunglasses, image distortions, different camera positioning, facial expressions, image rotations, facial hair, glasses, scars, makeup, colored lenses and filters, image abrasions, variable backgrounds, variable poses, variable distances, and variable hue, saturation and lighting (HSL).

Similarly, the fingerprint recognition embedding DNN’s training dataset is randomly augmented during training to add image distortions, different camera positioning, image rotations, scars, colored lenses and filters, image abrasions, variable backgrounds, variable poses, variable distances, and variable hue, saturation and lighting (HSL).

Finally, the voice audio dataset is randomly augmented during training to include signal variations (8-48kHz), background noise, variable microphones, variable noise-canceling algorithms, and variable human physiological conditions that affect voice including lack of sleep, smoking and alcohol.

### `4. Privacy and fully homomorphic encryption (FHE)`
Fully homomorphic encryption (FHE) allows computations to be carried out on ciphertext to generate encrypted match results. The use of complex, pre-trained embedding DNNs to generate real-valued, lower-dimensional distance-measurable 1-way FHE payloads is a relatively new technique first described by Streit and colleagues in 2017 [[link](https://arxiv.org/abs/1708.04726)] and patented by Private Identity in 2019, 2020, and 2021 (US Patents 10,419,221 and 10,721,070).

Embeddings produced by Private Identity’s embedding DNNs are anonymized, keyless, 1-way FHE payloads that are globally unique (i.e. no two embeddings are ever the same), positional arrays of 128 floating-point numbers that do not contain biological or behavioral characteristics, imagery or a template of any physiological, biological or behavioral trait. These embeddings are a form of 1-way encryption in that they cannot be used to recreate the initial input data but are distance measurable so the similarity between embeddings can be calculated and classified by a DNN.

IEEE 2410-2021 Standard for Biometric Privacy provides comprehensive technical and policy standards for Private Identity and other biometric FHE identity systems. IEEE 2410-2021 ensures: (1) biometric payloads are always 1-way fully homomorphically encrypted; (2) no PII is received by the SBP server; and (3) conforming 1-way FHE systems “do not incur GDPR, CCPA, BIPA or HIPAA privacy law obligations.” Private ID is certified compliant with IEEE 2410-2021 Standard for Biometric Privacy, ISO 27001, and ISO 9001. GMS Registrar provides the third-party accredited certification (3PAO).
### `5. Client security`
The Private ID client is a C++ shareable object (.so) built to secure the authentication process against adversaries willing to spend “any amount of money and effort” to defeat security. Specifically, the client is composed of immutable compiled native C++ binary object code, helper networks and embedding DNNs compiled using TensorFlow Lite into runnable C++ libraries, three layers of cryptography to protect communication with the backend, uninterruptible business functions, and a one-way authentication mechanism on the backend that only returns a UUID. The decentralized client operates with or without a network.

***Cryptography***. The Private ID client and backend use three levels of data confidentiality. At the Web layer, Private ID uses transport-level declarative security enforced by the container. The payloads are further encrypted with AES256 and inside each payload are the embeddings which are themselves one-way encryptions. The server has automatic and declarative transport decryption, followed by AES256 decryption to get to the 1-way encrypted payload (embeddings). The 1-way encrypted payload is then used in RESTFul enroll and predict. Additional safeguards are present in the container.

***Decentralized operation (“airplane mode”).*** The Private ID client caches AES256-encrypted FHE payloads locally (on-device) to operate in low- or no-bandwidth environments and improve horizontal scalability. A modern phone can authenticate up to 100 users without latency (a laptop can authenticate up to 3500 users) without GPUs or on-device training.

***W3C WebAssembly (Wasm)***. The Private ID shareable object in a Wasm wrapper runs on all major browsers using immutable compiled native C++ binary object code in a stack-based VM in user-space that is not observable at runtime and is protected from control-flow hijacking attacks and direct code injection attacks. Irrespective of the security framework and the isolated environment of the code, the solution seamlessly adheres to the normal DOM interface, is memory sandboxed and capability constrained.

***C# SDK, Android SDK & Python SDK.*** The Private ID shareable object is available in a C#, Android, and Python wrapper to support any phone, device, embedded device or platform.

***Business functions***. The Private ID client provides five uninterruptible business processes: is_valid(), predict(), enroll(), compare() and delete(). The client maintains full control of the identification, verification, and authentication journey to prevent control flow and code injection. It validates the biometric, transforms the sample to an embedding, calls local storage, secures the transport layer with three layers of cryptography, calls the Web Tier, and returns the encrypted result (uuid and guid).
### `6. 1:n vector match`
Modern 1:n vector search systems require indexing the costs (distances) between every set of vectors. These solutions are exponential or NP, require large compute, and are bounded by gallery size. Examples of NP vector search solutions are Facebook’s Faiss and Google Vertex AI.

Private ID solves 1:n vector match without indexes and achieves an O(1) solution by training a feed-forward neural network with embeddings and labels. This fully connected neural network (FCNN) accurately infers the correct label when provided never-before-seen embeddings in 60ms *constant time* irrespective of gallery size.
### `7. Unbiased algorithms`
Private ID uses an ethnically balanced facial training dataset and homogenized lighting algorithms to prevent discrimination based on race, age, gender, or ethnicity. Accurately identifies all subgroups (IR≥99.71%) on Private ID’s DIF-CELEB-1M Diversity in Faces evaluation set.

In response to a customer request, Private Identity built the Diversity in Faces (DIF-CELEB-1M) evaluation dataset with a subclass distribution that closely resembled the US population. Specifically, DIF-CELEB-1M contains 2,049 celebrity classes (461,322 facial images) distributed 14% Black, 6% Asian, 53% White, 23% Hispanic, and 4% Other.

The evaluation found the Private Identity recognition algorithm performed without bias across all racial subgroups, generated no false positive (Type I) errors and 0.25% false negative (Type II) errors. Study results are posted here in this [Google [Doc](https://docs.google.com/document/d/1bMQ3S3rQm8yuR_MnI-GUUL3PfwfWBfclyEAcKbebtbs/edit?usp=sharing)].